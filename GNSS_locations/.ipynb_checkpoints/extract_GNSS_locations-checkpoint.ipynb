{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c070415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_GNSS_loc2(data_dir,output_dir,eqnames):\n",
    "    '''\n",
    "    Extract GNSS locations given the working directory and the name of the earthquake.\n",
    "    Input:\n",
    "        working_dir:       Float with the station/site longitude\n",
    "        etq_name:          Float with the station/site latitude\n",
    "        \n",
    "    Output:\n",
    "        st_name:           Station name (net.sta)\n",
    "        st_lat:            Station latitude\n",
    "        st_lon:            Station longitude\n",
    "        st_elv:            Station elevation\n",
    "        st_samp_rate:      Sampling rate\n",
    "        st_gain:           Station gain\n",
    "        st_units:          Units\n",
    "    '''\n",
    "    \n",
    "    from glob import glob\n",
    "    from os import environ\n",
    "    import numpy as np\n",
    "    import os\n",
    "   \n",
    "    # concatenate infile name\n",
    "    infile = data_dir + '/' + eqnames + '/' + eqnames + '_disp.chan'\n",
    "\n",
    "    # export infile variable as an environment variable\n",
    "    environ['infile'] = infile\n",
    "\n",
    "    # extract parameters from infile with awk\n",
    "    st_name = !awk 'NR>1 {if ($4 == \"LXZ\") print $2}' \"$infile\"\n",
    "    st_lat = !awk 'NR>1 {if ($4 == \"LXZ\") print $5}' \"$infile\"\n",
    "    st_lon = !awk 'NR>1 {if ($4 == \"LXZ\") print $6}' \"$infile\"\n",
    "    st_elv = !awk 'NR>1 {if ($4 == \"LXZ\") print $7}' \"$infile\"\n",
    "    st_samp_rate = !awk 'NR>1 {if ($4 == \"LXZ\") print $8}' \"$infile\"\n",
    "    st_gain = !awk 'NR>1 {if ($4 == \"LXZ\") print $9}' \"$infile\"\n",
    "    st_unit = !awk 'NR>1 {if ($4 == \"LXZ\") print $10}' \"$infile\"\n",
    "    \n",
    "    # write GNSS locations to file\n",
    "    write_gflist_file(output_dir,eqnames,st_name, st_lat, st_lon)\n",
    "    \n",
    "    return st_name, st_lat, st_lon, st_elv, st_samp_rate, st_gain, st_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3063a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ALL_GNSS_sta_to_file(output_dir,st_name, st_lat, st_lon, st_elv, st_samp_rate, st_gain, st_unit):\n",
    "\n",
    "    '''\n",
    "    This function writes the GNSS station info to file.\n",
    "\n",
    "    '''\n",
    "\n",
    "    file = open(output_dir + '/ALL_events.GNSS_locs.txt', \"w\")\n",
    "    \n",
    "    file.write('GNSS Locations for ALL the Earthquakes' + \"\\n\")\n",
    "    file.write('st_name' + \"\\t\" + 'lat' + \"\\t\" + 'lon' + \"\\t\" + \\\n",
    "                   'elv' + \"\\t\" + 'samp_rate' + \"\\t\" + 'gain'+ \"\\t\" + 'unit'+\"\\n\")\n",
    "    \n",
    "    for index in range(len(st_lat)):\n",
    "        file.write(st_name[index] + \"\\t\" + st_lat[index] + \"\\t\" + st_lon[index] + \"\\t\" + \\\n",
    "                   st_elv[index] + \"\\t\" + st_samp_rate[index] + \"\\t\" + st_gain[index]+ \"\\t\" + st_unit[index]+\"\\n\")\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1412fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_gflist_file(output_dir,eqnames,st_name, st_lat, st_lon):\n",
    "\n",
    "    '''\n",
    "    This function writes the GNSS station info to file.\n",
    "\n",
    "    '''\n",
    "\n",
    "    file = open(output_dir + '/'+ eqnames + '.gflist', \"w\")\n",
    "    \n",
    "    #file.write('GNSS Locations for '+ outfilename + ' Earthquake' + \"\\n\")\n",
    "    file.write('#station lon  lat \"static,disp,vel,tsun,strain\"'+\"\\n\")\n",
    "    \n",
    "    for index in range(len(st_lat)):\n",
    "        file.write(st_name[index] + \"\\t\" + st_lon[index] + \"\\t\" + st_lat[index] + \"\\t\" + '0 1 0 0 0 0'+\"\\n\")\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5af144f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 2 seconds\n"
     ]
    }
   ],
   "source": [
    "# Driver Code\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "data_dir = '/Users/oluwaseunfadugba/Documents/Projects/TsE_ValerieDiego/Data_GNSSdata'\n",
    "output_dir = '/Users/oluwaseunfadugba/Documents/Projects/TsE_ValerieDiego/TsE_1D_vs_3D/GNSS_locations'\n",
    "\n",
    "many_earthquake_names = ['E.Fukushima2011', 'Ibaraki2011', 'Iwate2011', 'Kumamoto2016',\n",
    "                    'Miyagi2011A', 'Miyagi2011B', 'N.Honshu2011',\n",
    "                    'N.Honshu2012', 'N.Honshu2013', 'Tohoku2011', 'Tokachi2003']\n",
    "\n",
    "# create output directory\n",
    "os.system('mkdir -p ' + output_dir);\n",
    "\n",
    "# Initialize variables\n",
    "st_names = []; st_lats = []; st_lons = []; st_elvs = [] \n",
    "st_samp_rate = []; st_gain = []; st_unit = [] \n",
    "n = 0\n",
    "\n",
    "# Extract GNSS locations for each earthquake and concatenate them\n",
    "for eqnames in many_earthquake_names:\n",
    "    n = n + 1\n",
    "    globals()['st_name%s' % n], globals()['st_lat%s' % n], globals()['st_lon%s' % n], \\\n",
    "        globals()['st_elv%s' % n], globals()['st_samp_rate%s' % n], globals() \\\n",
    "        ['st_gain%s' % n], globals()['st_unit%s' % n] =  extract_GNSS_loc2(data_dir,output_dir,eqnames)\n",
    "\n",
    "    st_names = st_names + globals()['st_name%s' % n]\n",
    "    st_lats = st_lats + globals()['st_lat%s' % n]   \n",
    "    st_lons = st_lons + globals()['st_lon%s' % n]   \n",
    "    st_elvs = st_elvs + globals()['st_elv%s' % n]\n",
    "    st_samp_rate = st_samp_rate + globals()['st_samp_rate%s' % n]\n",
    "    st_gain = st_gain + globals()['st_gain%s' % n]\n",
    "    st_unit = st_unit + globals()['st_unit%s' % n]\n",
    "    \n",
    "# Extract parameters for only the unique stations\n",
    "st_name_all, st_names_index = np.unique(np.array(st_names), return_index=True)\n",
    "st_lat_all = [st_lats[i] for i in st_names_index]\n",
    "st_lon_all = [st_lons[i] for i in st_names_index]\n",
    "st_elv_all = [st_elvs[i] for i in st_names_index]  \n",
    "st_samp_rate_all = [st_samp_rate[i] for i in st_names_index]\n",
    "st_gain_all = [st_gain[i] for i in st_names_index]\n",
    "st_unit_all = [st_unit[i] for i in st_names_index]\n",
    "\n",
    "# write GNSS locations to file\n",
    "write_ALL_GNSS_sta_to_file(output_dir,st_name_all, st_lat_all, st_lon_all, \\\n",
    "                       st_elv_all, st_samp_rate_all, st_gain_all, st_unit_all)\n",
    "\n",
    "end = time.time()\n",
    "time_elaps = end - start\n",
    "if time_elaps < 60:\n",
    "    print(f'Duration: {round(time_elaps)} seconds')\n",
    "else:\n",
    "    print(f'Duration: {round(time_elaps/60)} minutes')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b76ca7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E.Fukushima2011\n",
      "         network: AA\n",
      "         station: 0001\n",
      "        location: 00\n",
      "         channel: LXZ\n",
      "       starttime: 2011-04-11T08:16:02.000000Z\n",
      "         endtime: 2011-04-11T08:24:32.000000Z\n",
      "   sampling_rate: 1.0\n",
      "           delta: 1.0\n",
      "            npts: 511\n",
      "           calib: 1.0\n",
      "         _format: MSEED\n",
      "           mseed: AttribDict({'dataquality': 'D', 'number_of_records': 1, 'encoding': 'STEIM2', 'byteorder': '>', 'record_length': 4096, 'filesize': 4096})\n",
      " \n",
      "Ibaraki2011\n",
      "         network: AA\n",
      "         station: 0001\n",
      "        location: 00\n",
      "         channel: LXZ\n",
      "       starttime: 2011-03-11T06:15:24.000000Z\n",
      "         endtime: 2011-03-11T06:23:54.000000Z\n",
      "   sampling_rate: 1.0\n",
      "           delta: 1.0\n",
      "            npts: 511\n",
      "           calib: 1.0\n",
      "         _format: MSEED\n",
      "           mseed: AttribDict({'dataquality': 'D', 'number_of_records': 1, 'encoding': 'STEIM2', 'byteorder': '>', 'record_length': 4096, 'filesize': 4096})\n",
      " \n",
      "Iwate2011\n",
      "         network: AA\n",
      "         station: 0001\n",
      "        location: 00\n",
      "         channel: LXZ\n",
      "       starttime: 2011-03-11T06:08:43.000000Z\n",
      "         endtime: 2011-03-11T06:17:13.000000Z\n",
      "   sampling_rate: 1.0\n",
      "           delta: 1.0\n",
      "            npts: 511\n",
      "           calib: 1.0\n",
      "         _format: MSEED\n",
      "           mseed: AttribDict({'dataquality': 'D', 'number_of_records': 1, 'encoding': 'STEIM2', 'byteorder': '>', 'record_length': 4096, 'filesize': 4096})\n",
      " \n",
      "Kumamoto2016\n",
      "         network: AA\n",
      "         station: 0070\n",
      "        location: 00\n",
      "         channel: LXZ\n",
      "       starttime: 2016-04-15T16:24:15.000000Z\n",
      "         endtime: 2016-04-15T16:33:25.000000Z\n",
      "   sampling_rate: 1.0\n",
      "           delta: 1.0\n",
      "            npts: 551\n",
      "           calib: 1.0\n",
      "         _format: MSEED\n",
      "           mseed: AttribDict({'dataquality': 'D', 'number_of_records': 1, 'encoding': 'STEIM2', 'byteorder': '>', 'record_length': 4096, 'filesize': 4096})\n",
      " \n",
      "Miyagi2011A\n",
      "         network: AA\n",
      "         station: 0001\n",
      "        location: 00\n",
      "         channel: LXZ\n",
      "       starttime: 2011-03-09T02:44:23.000000Z\n",
      "         endtime: 2011-03-09T02:49:13.000000Z\n",
      "   sampling_rate: 1.0\n",
      "           delta: 1.0\n",
      "            npts: 291\n",
      "           calib: 1.0\n",
      "         _format: MSEED\n",
      "           mseed: AttribDict({'dataquality': 'D', 'number_of_records': 1, 'encoding': 'STEIM2', 'byteorder': '>', 'record_length': 4096, 'filesize': 4096})\n",
      " \n",
      "Miyagi2011B\n",
      "         network: AA\n",
      "         station: 0001\n",
      "        location: 00\n",
      "         channel: LXZ\n",
      "       starttime: 2011-04-07T14:32:33.000000Z\n",
      "         endtime: 2011-04-07T14:41:03.000000Z\n",
      "   sampling_rate: 1.0\n",
      "           delta: 1.0\n",
      "            npts: 511\n",
      "           calib: 1.0\n",
      "         _format: MSEED\n",
      "           mseed: AttribDict({'dataquality': 'D', 'number_of_records': 1, 'encoding': 'STEIM2', 'byteorder': '>', 'record_length': 4096, 'filesize': 4096})\n",
      " \n",
      "N.Honshu2011\n",
      "         network: AA\n",
      "         station: 0001\n",
      "        location: 00\n",
      "         channel: LXZ\n",
      "       starttime: 2011-03-11T06:25:34.000000Z\n",
      "         endtime: 2011-03-11T06:34:04.000000Z\n",
      "   sampling_rate: 1.0\n",
      "           delta: 1.0\n",
      "            npts: 511\n",
      "           calib: 1.0\n",
      "         _format: MSEED\n",
      "           mseed: AttribDict({'dataquality': 'D', 'number_of_records': 1, 'encoding': 'STEIM2', 'byteorder': '>', 'record_length': 4096, 'filesize': 4096})\n",
      " \n",
      "N.Honshu2012\n",
      "         network: AA\n",
      "         station: 0001\n",
      "        location: 00\n",
      "         channel: LXZ\n",
      "       starttime: 2012-12-07T08:18:10.000000Z\n",
      "         endtime: 2012-12-07T08:26:40.000000Z\n",
      "   sampling_rate: 1.0\n",
      "           delta: 1.0\n",
      "            npts: 511\n",
      "           calib: 1.0\n",
      "         _format: MSEED\n",
      "           mseed: AttribDict({'dataquality': 'D', 'number_of_records': 1, 'encoding': 'STEIM2', 'byteorder': '>', 'record_length': 4096, 'filesize': 4096})\n",
      " \n",
      "N.Honshu2013\n",
      "         network: AA\n",
      "         station: 0001\n",
      "        location: 00\n",
      "         channel: LXZ\n",
      "       starttime: 2013-10-25T17:10:08.000000Z\n",
      "         endtime: 2013-10-25T17:18:38.000000Z\n",
      "   sampling_rate: 1.0\n",
      "           delta: 1.0\n",
      "            npts: 511\n",
      "           calib: 1.0\n",
      "         _format: MSEED\n",
      "           mseed: AttribDict({'dataquality': 'D', 'number_of_records': 1, 'encoding': 'STEIM2', 'byteorder': '>', 'record_length': 4096, 'filesize': 4096})\n",
      " \n",
      "Tohoku2011\n",
      "         network: AA\n",
      "         station: 0001\n",
      "        location: 00\n",
      "         channel: LXZ\n",
      "       starttime: 2011-03-11T05:45:34.000000Z\n",
      "         endtime: 2011-03-11T05:50:24.000000Z\n",
      "   sampling_rate: 1.0\n",
      "           delta: 1.0\n",
      "            npts: 291\n",
      "           calib: 1.0\n",
      "         _format: MSEED\n",
      "           mseed: AttribDict({'dataquality': 'D', 'number_of_records': 1, 'encoding': 'STEIM2', 'byteorder': '>', 'record_length': 4096, 'filesize': 4096})\n",
      " \n",
      "Tokachi2003\n",
      "         network: AA\n",
      "         station: 0001\n",
      "        location: 00\n",
      "         channel: LXZ\n",
      "       starttime: 2003-09-25T19:50:07.000000Z\n",
      "         endtime: 2003-09-25T19:53:47.000000Z\n",
      "   sampling_rate: 1.0\n",
      "           delta: 1.0\n",
      "            npts: 221\n",
      "           calib: 1.0\n",
      "         _format: MSEED\n",
      "           mseed: AttribDict({'dataquality': 'D', 'number_of_records': 1, 'encoding': 'STEIM2', 'byteorder': '>', 'record_length': 4096, 'filesize': 4096})\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Extract earthquake parameters from the metadata\n",
    "from os import environ\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import obspy\n",
    "    \n",
    "data_dir = '/Users/oluwaseunfadugba/Documents/Projects/TsE_ValerieDiego/Data_GNSSdata'\n",
    "\n",
    "many_earthquake_names = ['E.Fukushima2011', 'Ibaraki2011', 'Iwate2011', 'Kumamoto2016',\n",
    "                    'Miyagi2011A', 'Miyagi2011B', 'N.Honshu2011',\n",
    "                    'N.Honshu2012', 'N.Honshu2013', 'Tohoku2011', 'Tokachi2003']\n",
    "                   \n",
    "                         \n",
    "for eqnames in many_earthquake_names:\n",
    "        \n",
    "    # Get an array of all channels with instruments with L or N instrument code and\n",
    "    #    an E, N, or Z direction\n",
    "    disp_files_E = np.array(sorted(glob(data_dir + '/' + eqnames +\n",
    "                                        '/disp/*.LXZ.mseed')))\n",
    "    \n",
    "    infile = disp_files_E[0]\n",
    "    \n",
    "    # Read file into a stream object\n",
    "    disp_raw = obspy.read(infile)\n",
    "    \n",
    "    print(eqnames)\n",
    "    print(disp_raw[0].stats)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc20d168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5528a5da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
